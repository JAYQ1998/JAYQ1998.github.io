# 高可用：负载均衡的常见算法有哪些？

> 相关面试题 ：
>
> - 服务端负载均衡一般怎么做？
> - 四层负载均衡和七层负载均衡的区别？
> - 负载均衡的常见算法有哪些？
> - 七层负载均衡常见解决方案有哪些？
> - 客户端负载均衡的常见解决方案有哪些？



## 负载均衡介绍 

负载均衡 指的是将用户请求分摊到不同的服务器上处理，以提高系统整体的并发处理能力。



下图是[《Java 面试指北》](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247519384&idx=1&sn=bc7e71af75350b755f04ca4178395b1a&chksm=cea1c353f9d64a458f797696d4144b4d6e58639371a4612b8e4d106d83a66d2289e7b2cd7431&token=660789642&lang=zh_CN&scene=21#wechat_redirect) 「高并发篇」中的一篇文章的配图，从图中可以看出，系统的商品服务部署了多份在不同的服务器上，为了实现访问商品服务请求的分流，我们用到了负载均衡。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/738439/1648639491443-78c6f8c4-077b-4918-a52b-041815dd66b3.png)





负载均衡是一种比较常用且实现简单的提高系统并发能力的手段，不论是单体架构的系统还是微服务架构的系统几乎都会用到。



## 负载均衡分类 

负载均衡可以简单分为 **服务端负载均衡** 和 **客户端负载均衡** 这两种。

服务端负载均衡涉及到的知识点更多，工作中遇到的也比较多，因为，我会花更多时间来介绍。



### 服务端负载均衡 

**服务端负载均衡** 主要应用在 系统外部请求 和 网关层 之间，可以使用 软件 或者 硬件 实现。

下图是我画的一个简单的基于 Nginx 的服务端负载均衡示意图：

![image.png](https://cdn.nlark.com/yuque/0/2022/png/738439/1648639502360-006c7fe0-74bc-498e-bc08-958863d234e9.png?x-oss-process=image%2Fresize%2Cw_531%2Climit_0)





**硬件负载均衡** 通过专门的硬件设备（比如 F5、A10、Array ）实现负载均衡功能。



硬件负载均衡的优势是性能很强且稳定，缺点就是实在是太贵了。像基础款的 F5 最低也要 20 多万，绝大部分公司是根本负担不起的，业务量不大的话，真没必要非要去弄个硬件来做负载均衡，用软件负载均衡就足够了！



在我们日常开发中，一般很难接触到硬件负载均衡，接触的比较多的还是 软件负载均衡 。软件负载均衡通过软件（比如 LVS、Nginx、HAproxy ）实现负载均衡功能，性能虽然差一些，但价格便宜啊！像基础款的 Linux 服务器也就几千，性能好一点的 2~3 万的就很不错了。



根据 OSI 模型，服务端负载均衡还可以分为：

- 二层负载均衡

- 三层负载均衡

- 四层负载均衡 - 传输层

- 七层负载均衡 - 应用层



最常见的是四层和七层负载均衡，因此，本文也是重点介绍这两种负载均衡。

![img](https://www.yuque.com/api/filetransfer/images?url=https%3A%2F%2Fguide-blog-images.oss-cn-shenzhen.aliyuncs.com%2Fgithub%2Fjavaguide%2Fosi%25E4%25B8%2583%25E5%25B1%2582%25E6%25A8%25A1%25E5%259E%258B.png&sign=462fc967cf9a7f8cd892c90587feb7c05f1629e22b0cfede7188b6b43a5dcd94)





**四层负载均衡** 工作在 OSI 模型第四层，也就是传输层，这一层的主要协议是 TCP/UDP，负载均衡器在这一层能够看到数据包里的源端口地址以及目的端口地址，会基于这些信息通过一定的负载均衡算法将数据包转发到后端真实服务器。



**七层负载均衡** 工作在 OSI 模型第七层，也就是应用层，这一层的主要协议是 HTTP 。这一层的负载均衡比四层负载均衡路由网络请求的方式更加复杂，它会读取报文的数据部分（比如说我们的 HTTP 部分的报文），然后根据读取到的数据内容（如 URL、Cookie）做出负载均衡决策。



七层负载均衡比四层负载均衡会消耗更多的性能，不过，也相对更加灵活，能够更加智能地路由网络请求，比如说你可以根据请求的内容进行优化如缓存、压缩、加密。



简单来说，四层负载均衡性能更强，七层负载均衡功能更强！



在工作中，我们通常会使用 Nginx 来做七层负载均衡，LVS(Linux Virtual Server 虚拟服务器， Linux 内核的 4 层负载均衡)来做四层负载均衡。



不过，LVS 这个绝大部分公司真用不上，像阿里、百度、腾讯、eBay 等大厂才会使用到，用的最多的还是 Nginx。



### 客户端负载均衡 

客户端负载均衡 主要应用于系统内部的不同的服务之间，可以使用现成的负载均衡组件来实现。



在客户端负载均衡中，客户端会自己维护一份服务器的地址列表，发送请求之前，客户端会根据对应的负载均衡算法来选择具体某一台服务器处理请求。



客户端负载均衡器和服务运行在同一个进程或者说 Java 程序里，不存在额外的网络开销。不过，客户端负载均衡的实现会受到编程语言的限制，比如说 Spring Cloud Load Balancer 就只能用于 Java 语言。



下图是我画的一个简单的基于 Spring Cloud Load Balancer 的客户端负载均衡示意图：

![image.png](https://cdn.nlark.com/yuque/0/2022/png/738439/1648639515579-07f05253-512d-4289-a47d-a9e4f00d8eaa.png?x-oss-process=image%2Fresize%2Cw_747%2Climit_0)





## 负载均衡常见算法 

### 随机法 

随机法 是最简单粗暴的负载均衡算法。

如果没有配置权重的话，所有的服务器被访问到的概率都是相同的。如果配置权重的话，权重越高的服务器被访问的概率就越大。



未加权重的随机算法适合于服务器性能相近的集群，其中每个服务器承载相同的负载。加权随机算法适合于服务器性能不等的集群，权重的存在可以使请求分配更加合理化。



不过，随机算法有一个比较明显的缺陷：部分机器在一段时间之内无法被随机到，毕竟是概率算法，就算是大家权重一样， 也可能会出现这种情况。



于是，轮询法 来了！



### 轮询法 

轮询法是挨个轮询服务器处理，也可以设置权重。

如果没有配置权重的话，每个请求按时间顺序逐一分配到不同的服务器处理。如果配置权重的话，权重越高的服务器被访问的次数就越多。

未加权重的轮询算法适合于服务器性能相近的集群，其中每个服务器承载相同的负载。加权轮询算法适合于服务器性能不等的集群，权重的存在可以使请求分配更加合理化。



### 一致性 Hash 法 

相同参数的请求总是发到同一台服务器处理，比如同个 IP 的请求。



### 最小连接法 

当有新的请求出现时，遍历服务器节点列表并选取其中活动连接数最小的一台服务器来响应当前请求。活动连接数可以理解为当前正在处理的请求数。



最小连接法可以尽可能最大地使请求分配更加合理化，提高服务器的利用率。不过，这种方法实现起来也最复杂，需要监控每一台服务器处理的请求连接数。



## 七层负载均衡常见方案

简单介绍两种项目中常用的七层负载均衡解决方案：DNS 解析和反向代理。



除了我介绍的这两种解决方案之外，HTTP 重定向等手段也可以用来实现负载均衡，不过，相对来说，还是 DNS 解析和反向代理用的更多一些，也更推荐一些。



### DNS 解析 

DNS 解析是比较早期的七层负载均衡实现方式，非常简单。



DNS 解析实现负载均衡的原理是这样的：在 DNS 服务器中为同一个主机记录配置多个 IP 地址，这些 IP 地址对应不同的服务器。当用户请求域名的时候，DNS 服务器采用轮询算法返回 IP 地址，这样就实现了轮询版负载均衡。



![img](https://www.yuque.com/api/filetransfer/images?url=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fimg_convert%2F6997605302452f07e8b28d257d349bf0.png&sign=00c7705df4730c5ba1dfbbad6e87652ece1558b0984e76a7265be4bc490ad948)





现在的 DNS 解析几乎都支持 IP 地址的权重配置，这样的话，在服务器性能不等的集群中请求分配会更加合理化。像我自己目前正在用的阿里云 DNS 就支持权重配置。



![img](https://www.yuque.com/api/filetransfer/images?url=https%3A%2F%2Fguide-blog-images.oss-cn-shenzhen.aliyuncs.com%2Fgithub%2Fjavaguide%2Faliyun-dns-weight-setting.png&sign=3062e2b1c029f3df62e87172e66a46fd6d8b844cfcddd69abc340ea979b5dcf2)



### 反向代理 

客户端将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器，获取数据后再返回给客户端。对外暴露的是反向代理服务器地址，隐藏了真实服务器 IP 地址。反向代理“代理”的是目标服务器，这一个过程对于客户端而言是透明的。



Nginx 就是最常用的反向代理服务器，它可以将接收到的客户端请求以一定的规则（负载均衡策略）均匀地分配到这个服务器集群中所有的服务器上。



反向代理负载均衡同样属于七层负载均衡。

![img](https://www.yuque.com/api/filetransfer/images?url=https%3A%2F%2Fguide-blog-images.oss-cn-shenzhen.aliyuncs.com%2Fgithub%2Fjavaguide%2Fnginx-load-balance.png&sign=0323869e17e40926a91907b235e554e5cbc5e054525edb50bbf73f4e4e09b006)





## 客户端负载均衡常见方案 



我们上面也说了，客户端负载均衡可以使用现成的负载均衡组件来实现。



Netflix Ribbon 和 Spring Cloud Load Balancer 就是目前 Java 生态最流行的两个负载均衡组件。



我更建议你使用 Spring 官方的 Spring Cloud LoadBalancer。Spring Cloud 2020.0.0 版本移除了 Netflix 除 Eureka 外的所有组件。Spring Cloud Hoxton.M2 是第一个支持 Spring Cloud Load Balancer 来替代 Netfix Ribbon 的版本。



我们早期学习微服务，肯定接触过 Netflix 公司开源的 Feign、Ribbon（客户端负载均衡）、Zuul、Hystrix（降级熔断）、Eureka（服务发现） 等知名的微服务系统构建所必须的组件，直到现在依然有非常非常多的公司在使用这些组件。不夸张地说，Netflix 公司引领了 Java 技术栈下的微服务发展。



![img](https://www.yuque.com/api/filetransfer/images?url=https%3A%2F%2Fguide-blog-images.oss-cn-shenzhen.aliyuncs.com%2Fgithub%2Fjavaguide%2FSpringCloudNetflix.png&sign=d1da0f242abaa3e86dff39d24ba621ab1f73eda5c088ea2bf457a8886bfdc68a)



那为什么 Spring Cloud 这么急着移除 Netflix 的组件呢？ 主要是因为在 2018 年的时候，Netflix 宣布其开源的核心组件 Hystrix、Ribbon、Zuul、Eureka 等进入维护状态，不再进行新特性开发，只修 BUG。于是，Spring 官方不得不考虑移除 Netflix 的组件。

Spring Cloud Alibaba 是一个不错的选择，尤其是对于国内的公司和个人开发者来说。



 参考 

●干货 | eBay 的 4 层软件负载均衡实现：https://mp.weixin.qq.com/s/bZMxLTECOK3mjdgiLbHj-g

●HTTP Load Balancing（Nginx 官方文档）：https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/

●深入浅出负载均衡 - vivo 互联网技术：https://www.cnblogs.com/vivotech/p/14859041.html